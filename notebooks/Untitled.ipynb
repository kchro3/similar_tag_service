{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6daa4e-a2e3-46fd-8a1a-24b150e48344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb97e3-eed3-400f-9b9a-99e69a569991",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = [\n",
    "    stem_text,\n",
    "    strip_tags,\n",
    "    strip_punctuation,\n",
    "    strip_multiple_whitespaces,\n",
    "    remove_stopwords,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6288221-c36a-49d3-b860-27cbca04a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "post_df = pd.read_json(\"data/preprocessed_data.jsonl\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b311a3-a35e-4dfb-b899-9b12017239d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = []\n",
    "for tags in post_df.head().tags.to_list():\n",
    "    flattened += tags\n",
    "flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff7f34-00f4-42a5-a670-0581533c676d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "canonical = OrderedDict()\n",
    "for word in flattened:\n",
    "    p_word = ' '.join(preprocess_string(word, FILTERS))\n",
    "    if p_word not in canonical:\n",
    "        canonical[p_word] = [word]\n",
    "    else:\n",
    "        canonical[p_word].append(word)\n",
    "canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d18680-ccc5-4f2f-a07e-9c99a19858fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for x in np.mean(np.array([[1,2,3],[2,1,3]]), axis=0):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5ce1b-aa12-4c09-8e83-c7a577b4b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertConfig, BertForMaskedLM\n",
    "\n",
    "from txtai.pipeline import HFTrainer\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size = 500,\n",
    "    hidden_size = 50,\n",
    "    num_hidden_layers = 2,\n",
    "    num_attention_heads = 2,\n",
    "    intermediate_size = 100,\n",
    ")\n",
    "\n",
    "model = BertForMaskedLM(config)\n",
    "model.save_pretrained(\"bert\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert\")\n",
    "\n",
    "train = HFTrainer()\n",
    "\n",
    "# Train model\n",
    "train((model, tokenizer), dataset, task=\"language-modeling\", output_dir=\"bert\",\n",
    "      fp16=True, per_device_train_batch_size=128, num_train_epochs=10,\n",
    "      dataloader_num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cddf4f-470a-4963-b568-1fb210966422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
